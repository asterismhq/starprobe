# Project Overview
- Purpose: Local FastAPI API that orchestrates an autonomous "deep research" workflow over web search results using pluggable LLM backends (Ollama default, MLX optional) to produce structured summaries and metadata.
- Tech stack: Python 3.12+, FastAPI, LangChain/LangGraph orchestration, httpx for async HTTP, uvicorn for serving, pydantic-settings for config, dependency injection container in `DependencyContainer`.
- Structure: Application code under `src/olm_d_rch/` split into `api` (FastAPI routes), `clients` (LLM/search integrations), `nodes` & `graph` (LangGraph flows), `services` (business logic), `config` for settings, and `sdk` for client package. Shared SDK `stl-conn` vendored as git submodule under `submodules/stl-conn`.
- Notable features: Uses DI container for wiring, supports multiple LLM backends via environment config, includes mock components and demo script; repo also packages a python SDK under `sdk/`. Submodule `stl-conn` provides connector to Stella service and is versioned independently.