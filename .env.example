# API Configuration
OLM_D_RCH_PROJECT_NAME=olm-d-rch
OLM_D_RCH_BIND_IP=127.0.0.1
OLM_D_RCH_BIND_PORT=8000
OLM_D_RCH_DEV_PORT=8001
OLM_D_RCH_TEST_PORT=8002

# LLM Backend Configuration
# Set to "mlx" to run with the MLX backend on Apple Silicon (requires mlx-lm).
OLM_D_RCH_LLM_BACKEND=ollama

# Ollama Configuration
OLLAMA_HOST=
# OLM_D_RCH_OLLAMA_MODEL=llama3.2:3b
OLM_D_RCH_OLLAMA_MODEL=tinyllama:1.1b

# MLX Configuration
# Update the model if you prefer a different MLX checkpoint.
MLX_MODEL=mlx-community/TinyLlama-1.1B-Chat-v1.0-4bit
USE_MOCK_MLX=False

# DuckDuckGo Search Configuration (optional)
# DDGS_REGION=wt-wt
# DDGS_SAFESEARCH=moderate
# DDGS_MAX_RESULTS=10

# Mock settings
USE_MOCK_OLLAMA=False
USE_MOCK_SEARCH=False
USE_MOCK_SCRAPING=False
